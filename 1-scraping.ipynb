{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80c9eea",
   "metadata": {},
   "source": [
    "# Notebook Web Scraping:  Approach to scrape data from a statistics website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e7fb3",
   "metadata": {},
   "source": [
    "We try to use the data from www.basketball-reference.com and scrape for the respective statitics of the basketball players.\n",
    "With the gained data we will analyze if a player is underpaid, overpaid or paid fairly in regard to their performance.\n",
    "\n",
    "As the scraping was a more sophisticated approach, we tried to make it work. However at the end we had to resolve it by using the export function of the basketball-reference.com website, to get out data in a dataframe.\n",
    "At one point the scraping did work, but very inconsistently. So we changed some of the code in order to make it reproducable every time. Resulting in it to not even completely work occasionally. The current status is that most part of the code is working correctly for the current year and at some stages even display the correct information. However the data at the very end is not being displayed due to an error. Also the scraping code for the multiple years prior to 2023 is running without any errors, but does not seem to actually scrape. Once calling the table, it is either empty or not existing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e1671d",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a1b0921",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import json, pickle\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import requests\n",
    "import lxml\n",
    "import html5lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b703f6",
   "metadata": {},
   "source": [
    "## Setting up the scraping for players data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd91bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents_and_punctuation(text):\n",
    "    '''preprocessing the player names'''\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError:\n",
    "        pass\n",
    "    text = unicodedata.normalize('NFD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode(\"utf-8\")\n",
    "    return f\"{text}\".replace('.','').replace(',','').replace(\"'\",'')\n",
    "\n",
    "def update_row_with_dict(df, data, idx):\n",
    "# updating cells with new entries by using a dictionary\n",
    "    for key, value in data.items():\n",
    "        df.at[idx, key] = value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec112ae",
   "metadata": {},
   "source": [
    "## Scrape player statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a809b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62741fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_player(playerurl, year):\n",
    "# Scraping data from basketball-reference.com by using the respective URL for each player.\n",
    "    \n",
    "    data = {}\n",
    "    prev_season = f\"{year-1}-{year-2000}\"\n",
    "    next_season = f\"{year}-{year-2000+1}\"\n",
    "    \n",
    "    playerresponse = requests.get(playerurl)\n",
    "    playerpage = playerresponse.text\n",
    "    playersoup = BeautifulSoup(playerpage, \"lxml\")\n",
    "\n",
    "    ## Get additonal data like Height and Weight:\n",
    "    \n",
    "    try:\n",
    "        script_text = playersoup.find('script', {'type': 'application/ld+json'}).getText()\n",
    "        biodata = json.loads(script_text)\n",
    "        weight = biodata.get('weight', {}).get('value', '').replace('lbs', '').strip()\n",
    "        height = biodata.get('height', {}).get('value', '')\n",
    "    except (AttributeError, KeyError, json.JSONDecodeError):\n",
    "        weight = np.nan\n",
    "        height = np.nan\n",
    "        \n",
    "    data['Weight']= weight\n",
    "    data['Height']= height\n",
    "\n",
    "    ## Getting most common game statistics:\n",
    "    \n",
    "    dfpergame = pd.read_html(f\"{playersoup.find(id='per_game')}\")[0]\n",
    "    dfpergame = dfpergame.drop_duplicates(subset=['Season'])\n",
    "    dfpergame = dfpergame.set_index('Season')\n",
    "\n",
    "    featurelist = ['Age', 'Tm', 'G', 'GS', 'MP', 'FG%', '3P', '3P%', '3PA', 'FT', 'FT%', 'FTA', 'ORB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PTS']\n",
    "\n",
    "    for feature in featurelist:\n",
    "        try:\n",
    "            data[feature] = dfpergame.at[prev_season, feature]\n",
    "        except KeyError:\n",
    "            data[feature] = np.nan\n",
    "\n",
    "    ## Get detailed game statistics:  \n",
    "\n",
    "    dfadvanced = pd.read_html(f\"{playersoup.find(id='advanced')}\")[0]\n",
    "    dfadvanced = dfadvanced.drop_duplicates(subset=['Season'])\n",
    "    dfadvanced = dfadvanced.set_index('Season')\n",
    "    \n",
    "    featurelist = ['USG%', 'TS%', 'PER', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']\n",
    "    \n",
    "    for feature in featurelist:\n",
    "        try: \n",
    "            data[feature] = dfadvanced.at[prev_season, feature] \n",
    "        except KeyError: \n",
    "            data[feature] = np.nan\n",
    "\n",
    "    # Get last year's and next year's salary\n",
    "    # If a player has played for more than one team, his salary is concatenated\n",
    "\n",
    "    placeholder = playersoup.select_one('#all_all_salaries .placeholder')\n",
    "    comment = next(elem for elem in placeholder.next_siblings if isinstance(elem, Comment))\n",
    "    table = BeautifulSoup(comment, 'lxml')\n",
    "\n",
    "    dfsalaries = pd.read_html(f\"{table.find(id='all_salaries')}\")[0]\n",
    "\n",
    "    try:\n",
    "        data['PrevSal'] = dfsalaries.loc[dfsalaries['Season'] == prev_season, 'Salary'].sum()\n",
    "    except (KeyError, TypeError):\n",
    "        data['PrevSal'] = np.nan\n",
    "\n",
    "    try:\n",
    "        data['NextSal'] = dfsalaries.loc[dfsalaries['Season'] == next_season, 'Salary'].sum()\n",
    "    except (KeyError, TypeError):\n",
    "        data['NextSal'] = np.nan\n",
    "               \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa278d",
   "metadata": {},
   "source": [
    "## Example player: Lebron James"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01fd7852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Weight': '250', 'Height': '6-9', 'Age': 38.0, 'Tm': 'LAL', 'G': 55.0, 'GS': 54.0, 'MP': 35.5, 'FG%': 0.5, '3P': 2.2, '3P%': 0.321, '3PA': 6.9, 'FT': 4.6, 'FT%': 0.768, 'FTA': 5.9, 'ORB': 1.2, 'TRB': 8.3, 'AST': 6.8, 'STL': 0.9, 'BLK': 0.6, 'TOV': 3.2, 'PTS': 28.9, 'USG%': 33.3, 'TS%': 0.583, 'PER': 23.9, 'OWS': 3.2, 'DWS': 2.4, 'WS': 5.6, 'WS/48': 0.138, 'OBPM': 5.5, 'DBPM': 0.6, 'BPM': 6.1, 'VORP': 4.0, 'PrevSal': '$44,474,988', 'NextSal': 0}\n"
     ]
    }
   ],
   "source": [
    "playerurl = 'https://www.basketball-reference.com/players/j/jamesle01.html'\n",
    "\n",
    "fayear = 2023 \n",
    "data = scrape_player(playerurl, fayear)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ecd28",
   "metadata": {},
   "source": [
    "## Scrape stats and salaries for all free agents in a given year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8eee5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_row_with_dict(df, data, idx):\n",
    "    for key in data.keys():\n",
    "        df.loc[idx, key] = data.get(key)\n",
    "\n",
    "def scrape_year(year):\n",
    "    # For calculating if a player is over or underpaid, we look at so called \"free agents\", as these are players\n",
    "    # who do not have a contract with a team for the next season. Meaning they will have to negotiate their salary based on their performance. \n",
    "    # Giving us a baseline of how much a player should earn for their performance. \n",
    "\n",
    "    free_agent_url = 'https://www.basketball-reference.com/contracts/players.html' + f\"{year}\"\n",
    "    # Checking which players do not have a contract for the next season\n",
    "\n",
    "    prev_season = f\"{year-1}-{year-2000}\"\n",
    "    response = requests.get(free_agent_url)\n",
    "    page = response.text\n",
    "    FAsoup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "    table = FAsoup.find('table')\n",
    "    rows = [row for row in table.find_all('tr')]  # tr tag is for rows\n",
    "    rows_data = [[td.get_text() for td in row.find_all('td')] for row in rows]\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i in range(1, len(rows)):\n",
    "        try:\n",
    "            print(\"Scraping row\", i)\n",
    "\n",
    "            name = rows_data[i][0]\n",
    "            name_year = f\"{name} {year - 1}\".replace(' ', '_')  # past year\n",
    "            name_year = strip_accents_and_punctuation(name_year)\n",
    "\n",
    "            pos = rows_data[i][1]        # Position/ role of the player\n",
    "            fatype = rows_data[i][3]     # Type (UFA, RFA)\n",
    "            oldteam = rows_data[i][4]    # As \"OTm\" in the dataframe\n",
    "            prevstats = rows_data[i][5]  # Previous Year Stats ('Did not play' if didn't play)\n",
    "            newteam = rows_data[i][7]    # As \"NTm\" in the dataframe\n",
    "\n",
    "            nameid = rows[i].find_all('td')[0].find('a')['href']\n",
    "\n",
    "            data = {\n",
    "                'Name': name, 'Pos': pos, 'Type': fatype, 'OTm': oldteam,\n",
    "                'PrevStats': prevstats, 'NTm': newteam, 'ID': nameid\n",
    "            }\n",
    "            update_row_with_dict(df, data, name_year)\n",
    "\n",
    "            playerurl = 'https://www.basketball-reference.com' + nameid\n",
    "            playerdict = scrape_player(playerurl, year) \n",
    "            update_row_with_dict(df, playerdict, name_year)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred for row {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    df['PrevYear'] = year - 1\n",
    "    df.index.name = 'NameYear'\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4936143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table not found for year 2017\n",
      "Table not found for year 2018\n",
      "Table not found for year 2019\n",
      "Table not found for year 2020\n",
      "Table not found for year 2021\n",
      "Table not found for year 2022\n",
      "Table not found for year 2023\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_row_with_dict(df, data, idx):\n",
    "    for key in data.keys():\n",
    "        df.loc[idx, key] = data.get(key)\n",
    "\n",
    "def scrape_year(year):\n",
    "    free_agent_url = 'https://www.basketball-reference.com/contracts/players.html' + f\"{year}\"\n",
    "    # Checking which players do not have a contract for the next season\n",
    "\n",
    "    prev_season = f\"{year-1}-{year-2000}\"\n",
    "    response = requests.get(free_agent_url)\n",
    "    page = response.text\n",
    "    FAsoup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "    table = FAsoup.find('table')\n",
    "    if table is None:\n",
    "        print(f\"Table not found for year {year}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = [row for row in table.find_all('tr')]  # tr tag is for rows\n",
    "    rows_data = [[td.get_text() for td in row.find_all('td')] for row in rows]\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i in range(1, len(rows)):\n",
    "        try:\n",
    "            print(\"Scraping row\", i)\n",
    "\n",
    "            name = rows_data[i][0]\n",
    "            name_year = f\"{name} {year - 1}\".replace(' ', '_')  # past year\n",
    "            name_year = strip_accents_and_punctuation(name_year)\n",
    "\n",
    "            pos = rows_data[i][1]        # Position/ role of the player\n",
    "            fatype = rows_data[i][3]     # Type (UFA, RFA)\n",
    "            oldteam = rows_data[i][4]    # As \"OTm\" in the dataframe\n",
    "            prevstats = rows_data[i][5]  # Previous Year Stats ('Did not play' if didn't play)\n",
    "            newteam = rows_data[i][7]    # As \"NTm\" in the dataframe\n",
    "\n",
    "            nameid = rows[i].find_all('td')[0].find('a')['href']\n",
    "\n",
    "            data = {\n",
    "                'Name': name, 'Pos': pos, 'Type': fatype, 'OTm': oldteam,\n",
    "                'PrevStats': prevstats, 'NTm': newteam, 'ID': nameid\n",
    "            }\n",
    "            update_row_with_dict(df, data, name_year)\n",
    "\n",
    "            playerurl = 'https://www.basketball-reference.com' + nameid\n",
    "            playerdict = scrape_player(playerurl, year)  # Assuming 'scrape_player' function is defined elsewhere\n",
    "            update_row_with_dict(df, playerdict, name_year)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred for row {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    df['PrevYear'] = year - 1\n",
    "    df.index.name = 'NameYear'\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "df2016 = scrape_year(2017)\n",
    "df2017 = scrape_year(2018)\n",
    "df2018 = scrape_year(2019)\n",
    "df2019 = scrape_year(2020)\n",
    "df2020 = scrape_year(2021)\n",
    "\n",
    "#added the following 2 lines of code\n",
    "df2021 = scrape_year(2022)\n",
    "df2022 = scrape_year(2023)\n",
    "\n",
    "df2022.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd6d45",
   "metadata": {},
   "source": [
    "## Scrape last years of free agent stats and salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85a990cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020 = pd.read_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\df2020_merged.csv')\n",
    "df2021 = pd.read_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\df2021_merged.csv')\n",
    "df2022 = pd.read_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\df2022_merged.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02b00971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table not found for year 2017\n",
      "Table not found for year 2018\n",
      "Table not found for year 2019\n",
      "Table not found for year 2020\n",
      "Table not found for year 2021\n",
      "Table not found for year 2022\n",
      "Table not found for year 2023\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2016 = scrape_year(2017)\n",
    "df2017 = scrape_year(2018)\n",
    "df2018 = scrape_year(2019)\n",
    "df2019 = scrape_year(2020)\n",
    "df2020 = scrape_year(2021)\n",
    "\n",
    "#added the following 2 lines of code\n",
    "df2021 = scrape_year(2022)\n",
    "df2022 = scrape_year(2023)\n",
    "\n",
    "df2022.head(3)\n",
    "# Note that for df2020 in particular, NextSal data cannot be obtained this way and is just listed as \"0.0\".  \n",
    "# We will obtain in in a different way in Notebook 2 and populate the field in Notebook 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3ad8b5",
   "metadata": {},
   "source": [
    "# (2) Scrape Player Stats and Salaries:  Current Year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c825673",
   "metadata": {},
   "source": [
    "## Scrape player stats:  current year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3fa88c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
      "       '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%',\n",
      "       'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', '3PAr',\n",
      "       'AST%', 'BLK%', 'BPM', 'DBPM', 'DRB%', 'DWS', 'FTr', 'OBPM', 'ORB%',\n",
      "       'OWS', 'PER', 'STL%', 'TOV%', 'TRB%', 'TS%', 'USG%', 'VORP', 'WS',\n",
      "       'WS/48'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>...</th>\n",
       "      <th>OWS</th>\n",
       "      <th>PER</th>\n",
       "      <th>STL%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>TS%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>VORP</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>529</td>\n",
       "      <td>Justise Winslow</td>\n",
       "      <td>PF</td>\n",
       "      <td>26</td>\n",
       "      <td>POR</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>26.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>.466</td>\n",
       "      <td>14.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>OG Anunoby</td>\n",
       "      <td>SF</td>\n",
       "      <td>25</td>\n",
       "      <td>TOR</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>35.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>13.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>.586</td>\n",
       "      <td>19.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>138</td>\n",
       "      <td>Jalen Duren</td>\n",
       "      <td>C</td>\n",
       "      <td>19</td>\n",
       "      <td>DET</td>\n",
       "      <td>67</td>\n",
       "      <td>31</td>\n",
       "      <td>24.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>16.5</td>\n",
       "      <td>19.7</td>\n",
       "      <td>.655</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>148</td>\n",
       "      <td>Simone Fontecchio</td>\n",
       "      <td>SF</td>\n",
       "      <td>27</td>\n",
       "      <td>UTA</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.1</td>\n",
       "      <td>.495</td>\n",
       "      <td>20.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>518</td>\n",
       "      <td>Jalen Williams</td>\n",
       "      <td>SG</td>\n",
       "      <td>21</td>\n",
       "      <td>OKC</td>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>30.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7.9</td>\n",
       "      <td>.601</td>\n",
       "      <td>18.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>.119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rk             Player Pos Age   Tm   G  GS    MP   FG   FGA  ...   OWS  \\\n",
       "692  529    Justise Winslow  PF  26  POR  29  11  26.8  2.8   6.8  ...  -0.1   \n",
       "15    14         OG Anunoby  SF  25  TOR  67  67  35.6  6.3  13.2  ...   1.8   \n",
       "183  138        Jalen Duren   C  19  DET  67  31  24.9  3.9   5.9  ...   2.9   \n",
       "200  148  Simone Fontecchio  SF  27  UTA  52   6  14.7  2.2   6.0  ...  -0.4   \n",
       "680  518     Jalen Williams  SG  21  OKC  75  62  30.3  5.5  10.6  ...   3.0   \n",
       "\n",
       "      PER STL%  TOV%  TRB%   TS%  USG%  VORP    WS   WS/48  \n",
       "692   9.3  1.9  17.0  10.7  .466  14.2  -0.2   0.4    .022  \n",
       "15   14.6  2.7  12.1   7.9  .586  19.5   1.5   4.7    .094  \n",
       "183  17.3  1.3  16.5  19.7  .655  14.3   0.5   4.5    .129  \n",
       "200   8.0  0.9  10.5   6.1  .495  20.2  -0.6  -0.1  -0.004  \n",
       "680  15.6  2.1  12.3   7.9  .601  18.4   1.3   5.6    .119  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  Per-Game Stats\n",
    "\n",
    "url_pergame = 'https://www.basketball-reference.com/leagues/NBA_2023_per_game.html'\n",
    "\n",
    "def scrape_current_season_stats_pergame(url):\n",
    "    '''Get current season stats for all players from basketball-reference.com\n",
    "    '''\n",
    "    data = {}\n",
    "  \n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "    df = pd.read_html(f\"{soup.find(id='all_per_game_stats')}\")[0]\n",
    "    return df\n",
    "\n",
    "##  Advanced Stats\n",
    "\n",
    "url_advanced = 'https://www.basketball-reference.com/leagues/NBA_2023_advanced.html'\n",
    "\n",
    "def scrape_current_season_stats_advanced(url):\n",
    "    '''Get current season stats for all players from basketball-reference.com\n",
    "    '''\n",
    "    data = {}\n",
    "  \n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "    df = pd.read_html(f\"{soup.find(id='advanced_stats')}\")[0]\n",
    "    return df\n",
    "\n",
    "dfpergame = scrape_current_season_stats_pergame(url_pergame)\n",
    "dfadvanced = scrape_current_season_stats_advanced(url_advanced)\n",
    "\n",
    "## Merge per-game and advanced stats\n",
    "\n",
    "cols_to_use = dfadvanced.columns.difference(dfpergame.columns)\n",
    "dfcurrentstats = pd.merge(dfpergame, dfadvanced[cols_to_use], left_index=True, right_index=True, how='outer')\n",
    "dfcurrentstats = dfcurrentstats.drop(['Unnamed: 19','Unnamed: 24'], axis=1)\n",
    "print(dfcurrentstats.columns)\n",
    "dfcurrentstats.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4749c8cb",
   "metadata": {},
   "source": [
    "## Scrape player salaries:  current year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cac266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_team(team):\n",
    "    \n",
    "    url = 'https://www.basketball-reference.com/contracts/' + team + '.html'\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "    df = pd.read_html(f\"{soup.find(id='contracts')}\")[0]\n",
    "        \n",
    "    df.columns = df.columns.to_flat_index()\n",
    "    df.rename(columns= {df.columns[0]: 'Name', df.columns[2]: 'CurrentSalary'}, inplace=True)\n",
    "    df['CurrentTeam'] = team\n",
    "\n",
    "    df = df.drop(df.tail(1).index)\n",
    "    df = df[['Name','CurrentSalary','CurrentTeam']]\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e151692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>CurrentSalary</th>\n",
       "      <th>CurrentTeam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>$47,607,350</td>\n",
       "      <td>LAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>$40,600,080</td>\n",
       "      <td>LAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D'Angelo Russell</td>\n",
       "      <td>$17,307,693</td>\n",
       "      <td>LAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rui Hachimura</td>\n",
       "      <td>$15,740,741</td>\n",
       "      <td>LAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austin Reaves</td>\n",
       "      <td>$12,015,150</td>\n",
       "      <td>LAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gabe Vincent</td>\n",
       "      <td>$10,500,000</td>\n",
       "      <td>LAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jarred Vanderbilt</td>\n",
       "      <td>$4,698,000</td>\n",
       "      <td>LAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Taurean Prince</td>\n",
       "      <td>$4,516,000</td>\n",
       "      <td>LAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jalen Hood-Schifino</td>\n",
       "      <td>$3,695,040</td>\n",
       "      <td>LAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jaxson Hayes</td>\n",
       "      <td>$2,165,000</td>\n",
       "      <td>LAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cam Reddish</td>\n",
       "      <td>$2,165,000</td>\n",
       "      <td>LAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Max Christie</td>\n",
       "      <td>$1,719,864</td>\n",
       "      <td>LAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name CurrentSalary CurrentTeam\n",
       "0          LeBron James   $47,607,350         LAL\n",
       "1         Anthony Davis   $40,600,080         LAL\n",
       "2      D'Angelo Russell   $17,307,693         LAL\n",
       "3         Rui Hachimura   $15,740,741         LAL\n",
       "4         Austin Reaves   $12,015,150         LAL\n",
       "5          Gabe Vincent   $10,500,000         LAL\n",
       "6     Jarred Vanderbilt    $4,698,000         LAL\n",
       "7        Taurean Prince    $4,516,000         LAL\n",
       "8   Jalen Hood-Schifino    $3,695,040         LAL\n",
       "9          Jaxson Hayes    $2,165,000         LAL\n",
       "10          Cam Reddish    $2,165,000         LAL\n",
       "11         Max Christie    $1,719,864         LAL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = scrape_team('LAL')\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0f5df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_team(team):\n",
    "    url = f'https://www.basketball-reference.com/contracts/{team}.html'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 404:\n",
    "        print(f\"Table not found for team: {team}\")\n",
    "        return pd.DataFrame(columns=['Name', 'CurrentSalary', 'CurrentTeam'])\n",
    "\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    df = pd.read_html(f\"{soup.find(id='contracts')}\")[0]\n",
    "    df.columns = df.columns.to_flat_index()\n",
    "    df.rename(columns={df.columns[0]: 'Name', df.columns[2]: 'CurrentSalary'}, inplace=True)\n",
    "    df['CurrentTeam'] = team_short [team]\n",
    "    \n",
    "\n",
    "    team_short =  {\n",
    "    'IND': 'Indiana Pacers',          'GSW': 'Golden State Warriors' ,\n",
    "    'TOR': 'Toronto Raptors',         'MEM': 'Memphis Grizzlies',\n",
    "    'MIA': 'Miami Heat',              'BRK': 'Brooklyn Nets',\n",
    "    'POR': 'Portland Trailblazers',   'PHO': 'Phoenix Suns',\n",
    "    'NOP': 'New Orleans Pelicans',    'MIL': 'Milwaukee Bucks',\n",
    "    'DET': 'Detroit Pistons' ,        'LAL': 'Los Angeles Lakers',\n",
    "    'ORL': 'Orlando Magic',           'HOU': 'Houston Rockets' ,\n",
    "    'WAS': 'Washington Wizards' ,     'ATL': 'Atlanta Hawks',\n",
    "    'UTA': 'Utah Jazz',               'SAC': 'Sacramento Kings',\n",
    "    'NYK': 'New York Knicks',         'DEN': 'Denver Nuggets' ,\n",
    "    'PHI': 'Philadephia 76ers' ,      'SAS': 'San Antonio Spurs' ,\n",
    "    'LAC': 'Los Angeles Clippers',    'OKC': 'Oklahoma City Thunder' ,\n",
    "    'MIN': 'Minnesota Timberwolves',  'CLE': 'Cleveland Cavaliers' ,\n",
    "    'CHO': 'Charlotte Hornets',       'CHI': 'Chicago Bulls' ,\n",
    "    'BOS': 'Boston Celtics',          'DAL':'Dallas Mavericks',\n",
    "    }\n",
    "\n",
    "    teams = list(team_short.keys())  #We just need the team names as used in the urls\n",
    "\n",
    "    df = pd.DataFrame(columns=['Name', 'CurrentSalary', 'CurrentTeam'])\n",
    "\n",
    "    for team in teams:\n",
    "        df_team = scrape_team(team)\n",
    "        df = pd.concat([df, df_team])\n",
    "    \n",
    "    df.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b060a9b2",
   "metadata": {},
   "source": [
    "## Create player-to-url dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf5fa5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precious Achiuwa': '/players/a/achiupr01.html',\n",
       " 'Steven Adams': '/players/a/adamsst01.html',\n",
       " 'Bam Adebayo': '/players/a/adebaba01.html',\n",
       " 'Ochai Agbaji': '/players/a/agbajoc01.html',\n",
       " 'Santi Aldama': '/players/a/aldamsa01.html'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.basketball-reference.com/leagues/NBA_2023_per_game.html'\n",
    "\n",
    "player_to_url = {}\n",
    "\n",
    "response = requests.get(url)\n",
    "page = response.text\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "\n",
    "table = soup.find('table')\n",
    "rows = [row for row in table.find_all('tr')]  # tr tag is for rows\n",
    "\n",
    "for row in rows[1:]:\n",
    "    try:\n",
    "        name = row.findAll('td')[0].getText()\n",
    "        nameid = row.findAll('td')[0].contents[0]['href']\n",
    "        if name not in player_to_url:\n",
    "            player_to_url[name] = nameid\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "{k: player_to_url[k] for k in list(player_to_url)[:5]}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f43f243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precious Achiuwa</td>\n",
       "      <td>/players/a/achiupr01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>/players/a/adamsst01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bam Adebayo</td>\n",
       "      <td>/players/a/adebaba01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ochai Agbaji</td>\n",
       "      <td>/players/a/agbajoc01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Santi Aldama</td>\n",
       "      <td>/players/a/aldamsa01.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name                         ID\n",
       "0  Precious Achiuwa  /players/a/achiupr01.html\n",
       "1      Steven Adams  /players/a/adamsst01.html\n",
       "2       Bam Adebayo  /players/a/adebaba01.html\n",
       "3      Ochai Agbaji  /players/a/agbajoc01.html\n",
       "4      Santi Aldama  /players/a/aldamsa01.html"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfplayer_to_url = pd.Series(player_to_url).to_frame().reset_index()\n",
    "dfplayer_to_url.rename(columns= {'index': 'Name',0: 'ID'}, inplace=True)\n",
    "dfplayer_to_url.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d41a7",
   "metadata": {},
   "source": [
    "## Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0575d5d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[39m.\u001b[39msample(\u001b[39m10\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[39m#check for correct data gathering\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.sample(10)\n",
    "#check for correct data gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\df2020_raw.csv')\n",
    "\n",
    "#added the following 3 lines of code\n",
    "df2021.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\df2021_raw.csv')\n",
    "df2022.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\df2022_raw.csv')\n",
    "\n",
    "\n",
    "dfcurrentstats.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\dfcurrentstats.csv')\n",
    "df.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\dfcurrentsalaries.csv')\n",
    "\n",
    "dfplayer_to_url.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\dfplayer_to_url.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
