{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80c9eea",
   "metadata": {},
   "source": [
    "# Notebook 1:  Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e7fb3",
   "metadata": {},
   "source": [
    "In this notebook we scrape www.basketball-reference.com for NBA player stats and salaries.\n",
    "Our scraping workflow has two parts:\n",
    "1.  **Past Years Data**: Using free agent lists for the last five years, scrape each listed player's previous season stats and his salary the following year.  These will form the features and targets, respectively, for our player market value model.\n",
    "2.  **Current Year Data**: Using the entire list of players who have played in the 2021-22 season, scrape each player's current season stats and salary.  The stats will be used in our web app to predict each player's current market value based on their stats, which can be compared with his actual current season salary to calculate his surplus value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e1671d",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a1b0921",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import requests\n",
    "import lxml\n",
    "import unicodedata\n",
    "import json, pickle\n",
    "import html5lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb91363",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd91bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents_and_punctuation(text):\n",
    "    '''Normalize player name spellings'''\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError: # unicode is a default on python 3 \n",
    "        pass\n",
    "    text = unicodedata.normalize('NFD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode(\"utf-8\")\n",
    "    return str(text).replace('.','').replace(',','').replace(\"'\",'')\n",
    "\n",
    "\n",
    "def update_row_with_dict(df,d,idx):\n",
    "    '''Update the entries of a row in a dataframe, \n",
    "       using a dictionary to supply the values'''\n",
    "    for key in d.keys():\n",
    "        df.loc[idx, key] = d.get(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b703f6",
   "metadata": {},
   "source": [
    "# (1) Scrape Player Stats and Salaries: Past Years\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec112ae",
   "metadata": {},
   "source": [
    "## Scrape individual player stats and salaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62741fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_player(playerurl, fa_year):\n",
    "    '''Get salaries and per-game stats from basketball-reference.com\n",
    "       Edge case if a player played on multiple teams in a year: \n",
    "           — stats: his total stats are given across all teams ('Tm'='TOT') \n",
    "           — salary: his salaries are concatenated (eg: \"$27,957,238$794,536\")\n",
    "    '''\n",
    "    \n",
    "    d = {}\n",
    "    prev_season = str(fa_year-1) + '-' + str(fa_year-2000)\n",
    "    next_season = str(fa_year) + '-' + str(fa_year-2000+1)\n",
    "    \n",
    "    playerresponse = requests.get(playerurl)\n",
    "    playerpage = playerresponse.text\n",
    "    playersoup = BeautifulSoup(playerpage, \"lxml\")\n",
    "\n",
    "    ## Get Height and Weight:\n",
    "    \n",
    "    try:\n",
    "        script_text = playersoup.find('script',{'type': 'application/ld+json'}).getText()\n",
    "        biodata = json.loads(script_text) # a dictionary!\n",
    "        weight = biodata['weight']['value'].replace('lbs','').strip()\n",
    "        height = biodata['height']['value']\n",
    "    except:\n",
    "        weight = np.nan\n",
    "        height = np.nan\n",
    "        \n",
    "    d['Weight']= weight\n",
    "    d['Height']= height\n",
    "\n",
    "    ## Get Basic Per-Game Stats:\n",
    "    \n",
    "    dfpergame = pd.read_html(str(playersoup.find(id='per_game')))[0]\n",
    "    dfpergame = dfpergame.drop_duplicates(subset=['Season'])\n",
    "    dfpergame = dfpergame.set_index('Season')\n",
    "\n",
    "    featurelist = ['Age', 'Tm', 'G', 'GS', 'MP', 'FG%', '3P', '3P%', '3PA', 'FT', 'FT%','FTA', 'ORB', 'TRB', \n",
    "                    'AST', 'STL', 'BLK', 'TOV', 'PTS']\n",
    "    \n",
    "    for feature in featurelist:\n",
    "        try: \n",
    "            d[feature] = dfpergame.loc[prev_season, feature] \n",
    "        except: \n",
    "            d[feature] = np.nan\n",
    "\n",
    "    ## Get Advanced Per-Game Stats:  \n",
    "\n",
    "    dfadvanced = pd.read_html(str(playersoup.find(id='advanced')))[0]\n",
    "    dfadvanced = dfadvanced.drop_duplicates(subset=['Season'])\n",
    "    dfadvanced = dfadvanced.set_index('Season')\n",
    "    \n",
    "    featurelist = ['USG%', 'TS%', 'PER', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']\n",
    "    \n",
    "    for feature in featurelist:\n",
    "        try: \n",
    "            d[feature] = dfadvanced.loc[prev_season, feature] \n",
    "        except: \n",
    "            d[feature] = np.nan\n",
    "\n",
    "    ## Get previous and next year's salary\n",
    "    #  — If the player was on one team, it will be a string that looks like \"$27,093,019\"\n",
    "    #  — If the player was on two teams, it will be a string that looks like \"$27,957,238$794,536\"\n",
    "    #  — For 2021 free agents, Next Salary is incorrect (need 2021-22 from current stats)\n",
    "    \n",
    "    placeholder = playersoup.select_one('#all_all_salaries .placeholder')\n",
    "    comment = next(elem for elem in placeholder.next_siblings if isinstance(elem, Comment))\n",
    "    table = BeautifulSoup(comment, 'lxml')\n",
    "\n",
    "    dfsalaries = pd.read_html(str(table.find(id=\"all_salaries\")))[0]\n",
    "    \n",
    "    try: \n",
    "        d['PrevSal'] = dfsalaries[dfsalaries['Season'] == prev_season]['Salary'].sum()\n",
    "    except: \n",
    "        d['PrevSal'] = np.nan\n",
    "    try: \n",
    "        d['NextSal'] = dfsalaries[dfsalaries['Season'] == next_season]['Salary'].sum()\n",
    "    except: \n",
    "        d['NextSal'] = np.nan\n",
    "               \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa278d",
   "metadata": {},
   "source": [
    "### Example player:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd7852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Weight': '253', 'Height': '6-10', 'Age': 25.0, 'Tm': 'NOP', 'G': 56.0, 'GS': 56.0, 'MP': 33.0, 'FG%': 0.517, '3P': 0.9, '3P%': 0.331, '3PA': 2.6, 'FT': 6.1, 'FT%': 0.794, 'FTA': 7.7, 'ORB': 3.1, 'TRB': 12.0, 'AST': 3.9, 'STL': 1.6, 'BLK': 2.4, 'TOV': 2.0, 'PTS': 25.9, 'USG%': 29.5, 'TS%': 0.597, 'PER': 30.3, 'OWS': 6.4, 'DWS': 3.1, 'WS': 9.5, 'WS/48': 0.247, 'OBPM': 7.1, 'DBPM': 2.3, 'BPM': 9.4, 'VORP': 5.3, 'PrevSal': '$25,434,262', 'NextSal': '$27,093,019'}\n"
     ]
    }
   ],
   "source": [
    "playerurl = 'https://www.basketball-reference.com/players/d/davisan02.html'\n",
    "\n",
    "fayear = 2019    # we get his stats for the previous season 2018-2019\n",
    "d = scrape_player(playerurl, fayear)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "030dd06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Weight': '207', 'Height': '6-4', 'Age': 28.0, 'Tm': 'WAS', 'G': 40, 'GS': 40, 'MP': 36.0, 'FG%': 0.451, '3P': 1.6, '3P%': 0.3, '3PA': 5.3, 'FT': 4.2, 'FT%': 0.833, 'FTA': 5.1, 'ORB': 1.0, 'TRB': 4.7, 'AST': 6.6, 'STL': 0.9, 'BLK': 0.4, 'TOV': 3.4, 'PTS': 23.2, 'USG%': 30.8, 'TS%': 0.539, 'PER': 17.5, 'OWS': 0.6, 'DWS': 0.7, 'WS': 1.4, 'WS/48': 0.046, 'OBPM': 2.0, 'DBPM': -1.2, 'BPM': 0.8, 'VORP': 1.0, 'PrevSal': '$33,724,200', 'NextSal': 0}\n"
     ]
    }
   ],
   "source": [
    "playerurl = 'https://www.basketball-reference.com/players/b/bealbr01.html'\n",
    "\n",
    "fayear = 2022    # we get his stats for the previous season 2018-2019\n",
    "d = scrape_player(playerurl, fayear)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2017fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "playerurl = 'https://www.basketball-reference.com/players/l/lavinza01.html'\n",
    "\n",
    "fayear = 2022    # we get his stats for the previous season 2018-2019\n",
    "d = scrape_player(playerurl, fayear)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "playerurl = 'https://www.basketball-reference.com/players/a/aytonde01.html'\n",
    "\n",
    "fayear = 2022    # we get his stats for the previous season 2018-2019\n",
    "d = scrape_player(playerurl, fayear)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03738849",
   "metadata": {},
   "outputs": [],
   "source": [
    "playerurl = 'https://www.basketball-reference.com/players/b/brunsja01.html'\n",
    "\n",
    "fayear = 2022    # we get his stats for the previous season 2018-2019\n",
    "d = scrape_player(playerurl, fayear)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "playerurl = 'https://www.basketball-reference.com/players/s/simonan01.html'\n",
    "\n",
    "fayear = 2022    # we get his stats for the previous season 2018-2019\n",
    "d = scrape_player(playerurl, fayear)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "playerurl = 'https://www.basketball-reference.com/players/d/dortlu01.html'\n",
    "\n",
    "fayear = 2022    # we get his stats for the previous season 2018-2019\n",
    "d = scrape_player(playerurl, fayear)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661d5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "playerurl = 'https://www.basketball-reference.com/players/s/sextoco01.html'\n",
    "\n",
    "fayear = 2022    # we get his stats for the previous season 2018-2019\n",
    "d = scrape_player(playerurl, fayear)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc4a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "playerurl = 'https://www.basketball-reference.com/players/n/nurkiju01.html'\n",
    "\n",
    "fayear = 2022    # we get his stats for the previous season 2018-2019\n",
    "d = scrape_player(playerurl, fayear)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33caf72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "playerurl = 'https://www.basketball-reference.com/players/h/hardeja01.html'\n",
    "\n",
    "fayear = 2022    # we get his stats for the previous season 2018-2019\n",
    "d = scrape_player(playerurl, fayear)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ecd28",
   "metadata": {},
   "source": [
    "## Scrape stats and salaries for all free agents in a given year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8eee5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_fa_year(fa_year):\n",
    "    '''Find all free agents in a given year and call the function \"scrape_player\" \n",
    "       for each of them to get their previous season stats\n",
    "    '''\n",
    "\n",
    "    FA_url = 'https://www.basketball-reference.com/friv/free_agents.cgi?year=' + str(fa_year) \n",
    "    prev_season = str(fa_year-1) + '-' + str(fa_year-2000)\n",
    "\n",
    "    response = requests.get(FA_url)\n",
    "    page = response.text\n",
    "    FAsoup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "    table = FAsoup.find('table')\n",
    "    rows = [row for row in table.find_all('tr')]  # tr tag is for rows\n",
    "    rows_data = [[td.getText() for td in rows[i].findAll('td')]\n",
    "                    for i in range(len(rows))]\n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i in range(1,len(rows)):\n",
    "        try:\n",
    "            name = rows_data[i][0]\n",
    "            name_year = (name + ' ' + str(fa_year-1)).replace(' ','_')  #prev year\n",
    "            name_year = strip_accents_and_punctuation(name_year)\n",
    "             \n",
    "            pos = rows_data[i][1]         #Pos\n",
    "            fatype = rows_data[i][3]     #Type (UFA, RFA)\n",
    "            oldteam = rows_data[i][4]    #OTm \n",
    "            prevstats = rows_data[i][5]  #Previous Year Stats  ('Did not play' if didn't play)\n",
    "            newteam = rows_data[i][7]    #NTm\n",
    "\n",
    "            nameid = rows[i].find_all('td')[0].find('a')['href']\n",
    "\n",
    "            d = {'Name': name,  'Pos': pos, 'Type': fatype, 'OTm': oldteam, \n",
    "                 'PrevStats': prevstats, 'NTm' : newteam, 'ID': nameid}\n",
    "            update_row_with_dict(df,d,name_year)\n",
    "        \n",
    "        \n",
    "            playerurl = 'https://www.basketball-reference.com' + nameid\n",
    "            playerdict = scrape_player(playerurl, fa_year)\n",
    "            \n",
    "            update_row_with_dict(df,playerdict,name_year)\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    df['PrevYear'] = fa_year-1\n",
    "    df.index.name = 'NameYear'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd6d45",
   "metadata": {},
   "source": [
    "## Scrape last 5 years of free agent stats and salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b00971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PrevYear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NameYear</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PrevYear]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This takes 1-2 minutes per year\n",
    "\n",
    "df2016 = scrape_fa_year(2017)\n",
    "df2017 = scrape_fa_year(2018)\n",
    "df2018 = scrape_fa_year(2019)\n",
    "df2019 = scrape_fa_year(2020)\n",
    "df2020 = scrape_fa_year(2021)\n",
    "\n",
    "#added the following 2 lines of code\n",
    "df2021 = scrape_fa_year(2022)\n",
    "df2022 = scrape_fa_year(2023)\n",
    "\n",
    "df2021.head(3)\n",
    "# Note that for df2020 in particular, NextSal data cannot be obtained this way and is just listed as \"0.0\".  \n",
    "# We will obtain in in a different way in Notebook 2 and populate the field in Notebook 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3ad8b5",
   "metadata": {},
   "source": [
    "# (2) Scrape Player Stats and Salaries:  Current Year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c825673",
   "metadata": {},
   "source": [
    "## Scrape player stats:  current year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fa88c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
      "       '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%',\n",
      "       'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', '3PAr',\n",
      "       'AST%', 'BLK%', 'BPM', 'DBPM', 'DRB%', 'DWS', 'FTr', 'OBPM', 'ORB%',\n",
      "       'OWS', 'PER', 'STL%', 'TOV%', 'TRB%', 'TS%', 'USG%', 'VORP', 'WS',\n",
      "       'WS/48'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>...</th>\n",
       "      <th>OWS</th>\n",
       "      <th>PER</th>\n",
       "      <th>STL%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>TS%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>VORP</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>341</td>\n",
       "      <td>Gabriel Lundberg</td>\n",
       "      <td>SG</td>\n",
       "      <td>27</td>\n",
       "      <td>PHO</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>13.6</td>\n",
       "      <td>8.5</td>\n",
       "      <td>.342</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>202</td>\n",
       "      <td>Hassani Gravett</td>\n",
       "      <td>PG</td>\n",
       "      <td>25</td>\n",
       "      <td>ORL</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>18.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>.629</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>246</td>\n",
       "      <td>Justin Holiday</td>\n",
       "      <td>SG</td>\n",
       "      <td>32</td>\n",
       "      <td>SAC</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>.488</td>\n",
       "      <td>15.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>329</td>\n",
       "      <td>Caris LeVert</td>\n",
       "      <td>SG</td>\n",
       "      <td>27</td>\n",
       "      <td>IND</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>31.1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>15.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>16.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>.530</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>288</td>\n",
       "      <td>Stanley Johnson</td>\n",
       "      <td>PF</td>\n",
       "      <td>25</td>\n",
       "      <td>LAL</td>\n",
       "      <td>48</td>\n",
       "      <td>27</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>.564</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>.079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rk            Player Pos Age   Tm   G  GS    MP   FG   FGA  ...   OWS  \\\n",
       "480  341  Gabriel Lundberg  SG  27  PHO   4   0  11.0  1.3   4.8  ...  -0.1   \n",
       "274  202   Hassani Gravett  PG  25  ORL   8   3  21.4  2.3   4.8  ...   0.1   \n",
       "339  246    Justin Holiday  SG  32  SAC  25  25  25.6  2.8   8.2  ...  -0.3   \n",
       "464  329      Caris LeVert  SG  27  IND  39  39  31.1  7.1  15.9  ...   1.1   \n",
       "401  288   Stanley Johnson  PF  25  LAL  48  27  22.8  2.4   5.2  ...   0.9   \n",
       "\n",
       "      PER STL%  TOV% TRB%   TS%  USG%  VORP   WS   WS/48  \n",
       "480   7.7  3.3  13.6  8.5  .342  21.5   0.0  0.0  -0.005  \n",
       "274  10.1  1.4  18.5  6.5  .629  12.3   0.0  0.3    .071  \n",
       "339   7.9  1.6   9.0  4.7  .488  15.7  -0.2  0.0    .004  \n",
       "464  16.3  1.4   9.9  6.9  .530  26.8   0.5  1.5    .060  \n",
       "401  10.5  1.9  11.0  7.6  .564  12.5  -0.2  1.8    .079  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  Per-Game Stats\n",
    "\n",
    "url_pergame = 'https://www.basketball-reference.com/leagues/NBA_2022_per_game.html'\n",
    "\n",
    "def scrape_current_season_stats_pergame(url):\n",
    "    '''Get current season stats for all players from basketball-reference.com\n",
    "    '''\n",
    "    d = {}\n",
    "  \n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "    df = pd.read_html(str(soup.find(id='all_per_game_stats')))[0]\n",
    "    return df\n",
    "\n",
    "##  Advanced Stats\n",
    "\n",
    "url_advanced = 'https://www.basketball-reference.com/leagues/NBA_2022_advanced.html'\n",
    "\n",
    "def scrape_current_season_stats_advanced(url):\n",
    "    '''Get current season stats for all players from basketball-reference.com\n",
    "    '''\n",
    "    d = {}\n",
    "  \n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "    df = pd.read_html(str(soup.find(id='advanced_stats')))[0]\n",
    "    return df\n",
    "\n",
    "dfpergame = scrape_current_season_stats_pergame(url_pergame)\n",
    "dfadvanced = scrape_current_season_stats_advanced(url_advanced)\n",
    "\n",
    "## Merge per-game and advanced stats\n",
    "\n",
    "cols_to_use = dfadvanced.columns.difference(dfpergame.columns)\n",
    "dfcurrentstats = pd.merge(dfpergame, dfadvanced[cols_to_use], left_index=True, right_index=True, how='outer')\n",
    "dfcurrentstats = dfcurrentstats.drop(['Unnamed: 19','Unnamed: 24'], axis=1)\n",
    "print(dfcurrentstats.columns)\n",
    "dfcurrentstats.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4749c8cb",
   "metadata": {},
   "source": [
    "## Scrape player salaries:  current year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cac266b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>CurrentSalary</th>\n",
       "      <th>CurrentTeam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kristaps Porziņģis</td>\n",
       "      <td>$36,016,200</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jayson Tatum</td>\n",
       "      <td>$32,600,060</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jaylen Brown</td>\n",
       "      <td>$30,723,215</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malcolm Brogdon</td>\n",
       "      <td>$22,500,000</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Derrick White</td>\n",
       "      <td>$18,107,143</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Robert Williams</td>\n",
       "      <td>$11,812,501</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Al Horford</td>\n",
       "      <td>$10,000,000</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Payton Pritchard</td>\n",
       "      <td>$4,037,277</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Luke Kornet</td>\n",
       "      <td>$2,413,304</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sam Hauser</td>\n",
       "      <td>$1,927,896</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jordan Walsh</td>\n",
       "      <td>$1,119,563</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Demetrius Jackson</td>\n",
       "      <td>$92,857</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name CurrentSalary CurrentTeam\n",
       "0   Kristaps Porziņģis   $36,016,200         BOS\n",
       "1         Jayson Tatum   $32,600,060         BOS\n",
       "2         Jaylen Brown   $30,723,215         BOS\n",
       "3      Malcolm Brogdon   $22,500,000         BOS\n",
       "4        Derrick White   $18,107,143         BOS\n",
       "5      Robert Williams   $11,812,501         BOS\n",
       "6           Al Horford   $10,000,000         BOS\n",
       "7     Payton Pritchard    $4,037,277         BOS\n",
       "8          Luke Kornet    $2,413,304         BOS\n",
       "9           Sam Hauser    $1,927,896         BOS\n",
       "10        Jordan Walsh    $1,119,563         BOS\n",
       "15   Demetrius Jackson       $92,857         BOS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def scrape_team(team):\n",
    "    '''Returns dataframe with 2021-22 salary for all players from basketball-reference.com\n",
    "    '''\n",
    "    \n",
    "    url = 'https://www.basketball-reference.com/contracts/' + team + '.html'\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "    df = pd.read_html(str(soup.find(id='contracts')))[0]\n",
    "        \n",
    "    df.columns = df.columns.to_flat_index()\n",
    "    df.rename(columns= {df.columns[0]: 'Name', df.columns[2]: 'CurrentSalary'}, inplace=True)\n",
    "    df['CurrentTeam'] = team\n",
    "\n",
    "    df = df.drop(df.tail(1).index)\n",
    "    df = df[['Name','CurrentSalary','CurrentTeam']]\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "test = scrape_team('BOS')\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0f5df6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "html5lib not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mName\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCurrentSalary\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCurrentTeam\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m team \u001b[39min\u001b[39;00m teams:\n\u001b[1;32m---> 24\u001b[0m     df_team \u001b[39m=\u001b[39m scrape_team(team)\n\u001b[0;32m     25\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df, df_team])\n\u001b[0;32m     27\u001b[0m df\u001b[39m.\u001b[39msample(\u001b[39m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m, in \u001b[0;36mscrape_team\u001b[1;34m(team)\u001b[0m\n\u001b[0;32m      7\u001b[0m page \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mtext\n\u001b[0;32m      8\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(page, \u001b[39m\"\u001b[39m\u001b[39mlxml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_html(\u001b[39mstr\u001b[39;49m(soup\u001b[39m.\u001b[39;49mfind(\u001b[39mid\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcontracts\u001b[39;49m\u001b[39m'\u001b[39;49m)))[\u001b[39m0\u001b[39m]\n\u001b[0;32m     12\u001b[0m df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mto_flat_index()\n\u001b[0;32m     13\u001b[0m df\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m {df\u001b[39m.\u001b[39mcolumns[\u001b[39m0\u001b[39m]: \u001b[39m'\u001b[39m\u001b[39mName\u001b[39m\u001b[39m'\u001b[39m, df\u001b[39m.\u001b[39mcolumns[\u001b[39m2\u001b[39m]: \u001b[39m'\u001b[39m\u001b[39mCurrentSalary\u001b[39m\u001b[39m'\u001b[39m}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Vincenzo\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py:1212\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend)\u001b[0m\n\u001b[0;32m   1208\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m   1210\u001b[0m io \u001b[39m=\u001b[39m stringify_path(io)\n\u001b[1;32m-> 1212\u001b[0m \u001b[39mreturn\u001b[39;00m _parse(\n\u001b[0;32m   1213\u001b[0m     flavor\u001b[39m=\u001b[39;49mflavor,\n\u001b[0;32m   1214\u001b[0m     io\u001b[39m=\u001b[39;49mio,\n\u001b[0;32m   1215\u001b[0m     match\u001b[39m=\u001b[39;49mmatch,\n\u001b[0;32m   1216\u001b[0m     header\u001b[39m=\u001b[39;49mheader,\n\u001b[0;32m   1217\u001b[0m     index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m   1218\u001b[0m     skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[0;32m   1219\u001b[0m     parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m   1220\u001b[0m     thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[0;32m   1221\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1222\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   1223\u001b[0m     decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[0;32m   1224\u001b[0m     converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[0;32m   1225\u001b[0m     na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[0;32m   1226\u001b[0m     keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[0;32m   1227\u001b[0m     displayed_only\u001b[39m=\u001b[39;49mdisplayed_only,\n\u001b[0;32m   1228\u001b[0m     extract_links\u001b[39m=\u001b[39;49mextract_links,\n\u001b[0;32m   1229\u001b[0m     dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[0;32m   1230\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Vincenzo\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py:977\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m retained \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[39mfor\u001b[39;00m flav \u001b[39min\u001b[39;00m flavor:\n\u001b[1;32m--> 977\u001b[0m     parser \u001b[39m=\u001b[39m _parser_dispatch(flav)\n\u001b[0;32m    978\u001b[0m     p \u001b[39m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[0;32m    980\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Vincenzo\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py:926\u001b[0m, in \u001b[0;36m_parser_dispatch\u001b[1;34m(flavor)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[39mif\u001b[39;00m flavor \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbs4\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhtml5lib\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    925\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _HAS_HTML5LIB:\n\u001b[1;32m--> 926\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mhtml5lib not found, please install it\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    927\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _HAS_BS4:\n\u001b[0;32m    928\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mBeautifulSoup4 (bs4) not found, please install it\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: html5lib not found, please install it"
     ]
    }
   ],
   "source": [
    "tm_to_team =  {\n",
    " 'TOR': 'Toronto Raptors',         'MEM': 'Memphis Grizzlies',\n",
    " 'MIA': 'Miami Heat',              'BRK': 'Brooklyn Nets',\n",
    " 'NOP': 'New Orleans Pelicans',    'MIL': 'Milwaukee Bucks',\n",
    " 'CLE': 'Cleveland Cavaliers' ,    'LAL': 'Los Angeles Lakers',\n",
    " 'ORL': 'Orlando Magic',           'HOU': 'Houston Rockets' ,\n",
    " 'WAS': 'Washington Wizards' ,     'PHO': 'Phoenix Suns',\n",
    " 'UTA': 'Utah Jazz',               'SAC': 'Sacramento Kings',\n",
    " 'CHO': 'Charlotte Hornets',       'CHI': 'Chicago Bulls' ,\n",
    " 'NYK': 'New York Knicks',         'DEN': 'Denver Nuggets' ,\n",
    " 'PHI': 'Philadephia 76ers' ,      'SAS': 'San Antonio Spurs' ,\n",
    " 'LAC': 'Los Angeles Clippers',    'OKC': 'Oklahoma City Thunder' ,\n",
    " 'MIN': 'Minnesota Timberwolves',  'DET': 'Detroit Pistons' ,\n",
    " 'IND': 'Indiana Pacers',          'GSW': 'Golden State Warriors' ,\n",
    " 'POR': 'Portland Trailblazers',   'ATL': 'Atlanta Hawks',\n",
    " 'BOS': 'Boston Celtics',          'DAL':'Dallas Mavericks',\n",
    " }\n",
    "\n",
    "teams = list(tm_to_team.keys())  #We just need the team names as used in the urls\n",
    "\n",
    "df = pd.DataFrame(columns=['Name', 'CurrentSalary', 'CurrentTeam'])\n",
    "\n",
    "for team in teams:\n",
    "    df_team = scrape_team(team)\n",
    "    df = pd.concat([df, df_team])\n",
    "    \n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9ccd44",
   "metadata": {},
   "source": [
    "There are a 16 duplicate names (same player, multiple teams/salaries).  We deal with it manually, keeping the entry corresponding to the actual current team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c8820b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>CurrentSalary</th>\n",
       "      <th>CurrentTeam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, CurrentSalary, CurrentTeam]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df.duplicated(subset = ['Name'])].sort_values(\"Name\")\n",
    "ids = df[\"Name\"]\n",
    "df[ids.isin(ids[ids.duplicated()])].sort_values(\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed4688c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1 = ((df.Name == 'Armoni Brooks') & ~(df.CurrentTeam == 'TOR'))\n",
    "mask2 = ((df.Name == 'Blake Griffin') & ~(df.CurrentTeam == 'BRK'))\n",
    "mask3 = ((df.Name == 'D.J. Augustin') & ~(df.CurrentTeam == 'LAL'))\n",
    "mask4 = ((df.Name == 'Danuel House Jr.') & ~(df.CurrentTeam == 'UTA'))\n",
    "mask5 = ((df.Name == 'DeAndre Jordan') & ~(df.CurrentTeam == 'PHI'))\n",
    "mask6 = ((df.Name == \"DeAndre' Bembry\") & ~(df.CurrentTeam == 'MIL'))\n",
    "mask7 = ((df.Name == 'DeMarcus Cousins') & ~(df.CurrentTeam == 'DEN'))\n",
    "mask8 = ((df.Name == 'Dewayne Dedmon') & ~(df.CurrentTeam == 'MIA'))\n",
    "mask9 = ((df.Name == 'Goran Dragić') & ~(df.CurrentTeam == 'BRK'))\n",
    "mask10 = ((df.Name == 'Isaiah Hartenstein') & ~(df.CurrentTeam == 'LAC'))\n",
    "mask11 = ((df.Name == 'Jevon Carter') & ~(df.CurrentTeam == 'MIL'))\n",
    "mask12 = ((df.Name == 'Kemba Walker') & ~(df.CurrentTeam == 'NYK'))\n",
    "mask13 = ((df.Name == 'Moses Brown') & ~(df.CurrentTeam == 'CLE'))\n",
    "mask14 = ((df.Name == 'Nicolas Batum') & ~(df.CurrentTeam == 'LAC'))\n",
    "mask15 = ((df.Name == 'Tomáš Satoranský') & ~(df.CurrentTeam == 'WAS'))\n",
    "mask16 = ((df.Name == 'Tristan Thompson') & ~(df.CurrentTeam == 'CHI'))\n",
    "\n",
    "df = df[~mask1 & ~mask2 & ~mask3 & ~mask4 & ~mask5 & ~mask6 & ~mask7  & ~mask8 & ~mask9\n",
    "           & ~mask10 & ~mask11 & ~mask12 & ~mask13 & ~mask14  & ~mask15 & ~mask16] \n",
    "\n",
    "dfcurrentsalaries = df.copy()\n",
    "dfcurrentsalaries.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b060a9b2",
   "metadata": {},
   "source": [
    "## Create player-to-url dictionary\n",
    "\n",
    "* Get the player page url for any player who played in a game this past season (this is mostly useful for easily creating hyperlinks in the final web app, and could also potentially disambiguate identically named players)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf5fa5f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(page, \u001b[39m\"\u001b[39m\u001b[39mlxml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m table \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m rows \u001b[39m=\u001b[39m [row \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m table\u001b[39m.\u001b[39;49mfind_all(\u001b[39m'\u001b[39m\u001b[39mtr\u001b[39m\u001b[39m'\u001b[39m)]  \u001b[39m# tr tag is for rows\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m rows[\u001b[39m1\u001b[39m:]:\n\u001b[0;32m     14\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "url = 'https://www.basketball-reference.com/leagues/NBA_2023_per_game.html'\n",
    "\n",
    "player_to_url = {}\n",
    "\n",
    "response = requests.get(url)\n",
    "page = response.text\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "\n",
    "table = soup.find('table')\n",
    "rows = [row for row in table.find_all('tr')]  # tr tag is for rows\n",
    "\n",
    "for row in rows[1:]:\n",
    "    try:\n",
    "        name = row.findAll('td')[0].getText()\n",
    "        nameid = row.findAll('td')[0].contents[0]['href']\n",
    "        if name not in player_to_url:\n",
    "            player_to_url[name] = nameid\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "{k: player_to_url[k] for k in list(player_to_url)[:5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43f243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precious Achiuwa</td>\n",
       "      <td>/players/a/achiupr01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>/players/a/adamsst01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bam Adebayo</td>\n",
       "      <td>/players/a/adebaba01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Santi Aldama</td>\n",
       "      <td>/players/a/aldamsa01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>/players/a/aldrila01.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                         ID\n",
       "0   Precious Achiuwa  /players/a/achiupr01.html\n",
       "1       Steven Adams  /players/a/adamsst01.html\n",
       "2        Bam Adebayo  /players/a/adebaba01.html\n",
       "3       Santi Aldama  /players/a/aldamsa01.html\n",
       "4  LaMarcus Aldridge  /players/a/aldrila01.html"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfplayer_to_url = pd.Series(player_to_url).to_frame().reset_index()\n",
    "dfplayer_to_url.rename(columns= {'index': 'Name',0: 'ID'}, inplace=True)\n",
    "dfplayer_to_url.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d41a7",
   "metadata": {},
   "source": [
    "# Save All Scraped Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e440036",
   "metadata": {},
   "source": [
    "df2016.to_csv(r'/Users/richardsihombing/Documents/BigDataNBA/data/df2016_raw.csv')\n",
    "df2017.to_csv(r'/Users/richardsihombing/Documents/BigDataNBA/data/df2017_raw.csv')\n",
    "df2018.to_csv(r'/Users/richardsihombing/Documents/BigDataNBA/data/df2018_raw.csv')\n",
    "df2019.to_csv(r'/Users/richardsihombing/Documents/BigDataNBA/data/df2019_raw.csv')\n",
    "df2020.to_csv(r'/Users/richardsihombing/Documents/BigDataNBA/data/df2020_raw.csv')\n",
    "\n",
    "#added the following 2 lines of code\n",
    "df2021.to_csv(r'/Users/richardsihombing/Documents/BigDataNBA/data/df2020_raw.csv')\n",
    "df2022.to_csv(r'/Users/richardsihombing/Documents/BigDataNBA/data/df2020_raw.csv')\n",
    "\n",
    "dfcurrentstats.to_csv(r'/Users/richardsihombing/Documents/BigDataNBA/data/dfcurrentstats.csv')\n",
    "dfcurrentsalaries.to_csv(r'/Users/richardsihombing/Documents/BigDataNBA/data/dfcurrentsalaries.csv')\n",
    "\n",
    "dfplayer_to_url.to_csv(r'/Users/richardsihombing/Documents/BigDataNBA/data/dfplayer_to_url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4ff650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2016.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\df2016_raw.csv')\n",
    "df2017.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\df2017_raw.csv')\n",
    "df2018.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\df2018_raw.csv')\n",
    "df2019.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\df2019_raw.csv')\n",
    "df2020.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\df2020_raw.csv')\n",
    "\n",
    "#added the following 2 lines of code\n",
    "df2021.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\df2021_raw.csv')\n",
    "df2022.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\df2022_raw.csv')\n",
    "\n",
    "dfcurrentstats.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\dfcurrentstats.csv')\n",
    "dfcurrentsalaries.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\dfcurrentsalaries.csv')\n",
    "\n",
    "dfplayer_to_url.to_csv(r'C:\\Users\\Vincenzo\\Documents\\Master 2. Semester\\GutHub_Sofi\\BigDataNBA\\data\\dfplayer_to_url.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
